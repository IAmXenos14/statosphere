# All of these fields are optional, as is this file itself,
#   in which case these values can be managed in the UI.

# The name of the stage.
project_name: "Statosphere"

tagline: "Give your bots variables and launch them into...the Stat-O-Sphere! (phere) (ere)"

creator_notes: "
This is a stage for creating custom variables and rules for stat-tracking, behavior reinforcement, or complex scenario implementation. 
_Up front, this is pretty experimental, and maybe not for the faint of heart, but if you've been thinking about playing with a stage of your own, this may be a less daunting entrypoint._ 
If you can't see all of the notes below, please refresh this page until the \"Show More\" prompt renders--there's a lot more to show.
<br>
<br>
This stage is comprised of four core elements:<br>
<ul>
<li>Variable definitions with per-turn, post-input, and post-response update options
<li>JavaScript function definitions for creating complex, re-usable logic
<li>Zero-shot classification rules to draw inferences from inputs or responses and apply updates to variables as a result
<li>Content modification rules which alter input, response, post-input/response (which are \"system messages\" that display in-chat but do not persist to the LLM), and stage directions (additional LLM instruction), all based on specified conditions
</ul>
<br>
**Example Applications**<br>
This stage has no default configuration and will do nothing on its own. However, through configuration, a wide variety of effects are possible:<br>
<ul>
<li>Stat tracking and display: use inference to roughly gauge changes present in the input or response and translate that into a number to apply to variables
<li>Scenario escalation: use perTurnUpdate to increase a turn variable, then add prompt rules to feed updated scenario data as time marches on--go crazy and use inference to adjust the pace of escalation
<li>Rule or behavior reinforcement: apply classifiers or keywords to remind the LLM of your bot's quirks when the user's input should trigger them
<li>Dynamic response guidance: use inference to detect the nature of the user's input and ask the bot to focus its writing in different ways: is the user examining something? Instruct the bot to be descriptive. Is the user trying to move on? Tell the bot to introduce the next scene.
<li>Input clean-up: use regex to strip bracketed LLM instruction from the user's input and embed it into stage directions so it doesn't appear in the chat and is only included in the current prompt
<li>Content generation: randomize values for variables to build procedural content--or use stage directions to have the LLM generate content in a format that the stage can read and remove from the bot's responses (this could be pretty iffy, depending on the user's settings)
<li>Show up one of my other stages: both [Crunchatize](https://venus.chub.ai/extensions/Ravenok/crunchatize-77a78ffcc6a6) and [Alien Infestation](https://venus.chub.ai/extensions/Ravenok/alien-infestation-04c7448f1d14) could be entirely achieved through the functionality offered here
<li>These are just ideas; there are likely all kinds of creative and insane applications
</ul>
<br>
**Build Your Own Experience**<br>
Chub's stage configuration UI was not quite prepared for the elaborate requirements of this stage, so the configuration modal here in Venus is a single blank where you will paste some JSON.
Don't worry! You don't have to (and shouldn't!) hand-build any JSON to paste in there; I've created [an external tool](https://lord-raven.github.io/statosphere-editor/) 
that will produce JSON that you can copy and paste into the stage's configuration. You can also drop configuration from your bot (or others'!) into the tool to make modifications.
<br>
<br>
There is a lot more information that I should cover here, but I have not had time to do so yet. For the moment, please see my example bots and the configuration of the stage on those bots; 
you can view this by starting a chat with one and looking at the active stages in the chat settings. You can copy and paste the JSON from the stage's configuration into the tool above to see how the stage has been set up for that bot.
<br>
<br>
These are just some brief notes for creating your own configurations, to tide folks over 'til I can more properly document things:
<ul>
<li>With the exception of the Functions section, most value/condition/update fields in this configuration are evaluated mathematical statements which use [MathJS](https://mathjs.org/index.html).
<ul>
<li>Look at the [functions supported by MathJS](https://mathjs.org/docs/reference/functions.html), as it's quite robust out of the box.
<li>Surround string values with quotation marks.
<li>You can reference your variables by name outside of strings.
<li>You can also reference variables both inside and outside of strings by surrounding them with {{double braces}}; this substitution is performed by the stage before the content is evaluated.
<li>As a result, you can use double braces to reference {{user}}, {{char}}, and {{content}} (which contains either the last input or response, depending upon when the evaluation is occurring).
</ul>
<li>The Functions section allows you to define JavaScript functions, which can then be leveraged in any of the other evaluated fields.
<ul>
<li>These functions do not have access to any of the variables you define unless you pass those variables to them.
<li>They do have access to other functions you define; the stage is identifying functional dependencies and injecting those for you.
</ul>
</ul>
<br>
**Order of Operations**<br>
For reference, the rules on this stage are applied in this order:<br>
<ul>
<li>User submits input
<ul>
<li>Per-turn variable operations are performed, in the order that variables are defined
<li>Classifiers with an input hypothesis are applied to the input, in the order that classifiers are defined
<li>Post-input variable operations are performed, in the order that variables are defined
<li>Input content modifications are executed, in the order that these modifications are defined
<li>Post-input message content modifications are executed, in the order that these modifications are defined
<li>Stage direction modifications are executed, in the order that these modifications are defined
</ul>
<li>Bot returns response
<ul>
<li>Classifiers with a response hypothesis are applied to the response, in the order that classifiers are defined
<li>Post-response variable operations are performed, in the order that variables are defined
<li>Response content modifications are executed, in the order that these modifications are defined
<li>Post-response message modifications are executed, in the order that these modifications are defined
</ul>
</ul>
<br>
**Inference Details**<br>
This stage makes API calls to a Hugging Face backend that I have set up to leverage a zero-shot classification model. 
If this backend is unavailable or some other error occurs in calling it, the stage will swap to applying a very small, local, zero-shot model.
<br>
<br>
The backend does not log requests, but the source code is not public at this time. 
I simply haven't messed with how to expose the source code without opening up the backend to other apps--I need to restrict usage to these stages and block unknown third parties. 
In the near future, I will try to swap the permissions so others can view the source and verify there's nothing nefarious for themselves (or learn to set up their own for their own stage).
<br>
<br>
Neither the local model nor the backend model are going to get you great results without carefully tuned prompts/labels/hypotheses/thresholds; 
it can be a struggle to get consistently decent evaluations, so this remains the weakpoint in the stage. 
Chub's stage timeout is also pretty short and that can cause the stage to make a second call or give up entirely if these inferences take too long. 
These are items that will hopefully be more addressable in the future.
<br>
<br>
**Pitfalls**<br>
As excited as I am to present this, it is, unfortunately, a \"bot-maker beware\" sort of stage. There are a number of items that could warrant concern, which you may wish to consider before working with this stage:<br>
<ul>
<li>Active development: I am planning to expand the feature set, and this comes with the potential to break your application of the stage.
<li>Venus exclusivity: remember that stages are a feature of the Venus front-end, and anyone playing your bot in another front-end will not benefit; you may wish to point this out in your creator notes, if you have used this stage to cultivate an intended experience.
<li>Obfuscation: the stage can implement some interesting behaviors, but those behaviors may no longer be represented within the bot's definition; savvy users can disable or inspect the bot's configuration, but most users are unlikely to even recognize that a stage is in play--consider mentioning it in your bot descriptions.
<li>Malicious intent: because the stage is nearly opaque and it does offer powerful options--including evaluation of custom JavaScript functions--, I have some nebulous concern about the potential for abuse.
<li>Inference backend: the zero-shot classification inference is being conducted on a Hugging Face-hosted backend. I manage this backend and I do not log requests, but it is still a third-party call that you may wish to avoid. If your configuration does not use classifications, the stage never even connects to this backend.
<li>Stages are a beta feature: I imagine this stage could be broken by future stage releases; bear in mind that your bot's experience could be negatively impacted in that event.
<li>Users can cheat: like other aspects of your bot, the user can make modifications to your stage configuration and deviate from your intended experience; this shouldn't be surprising to a bot-maker, but maybe you should keep it in mind.
</ul>
<br>
**What's Next?**<br>
This stage represents nearly all the essential features I feel I can achieve without further improvements to Venus's stage system. There is certainly room for further improvement within this (or with the configuration editor), 
but my primary outstanding goals are dependent upon presumed features that will hopefully become a reality some day. For instance, prompt templating improvements could empower the stage to make additional calls to the LLM, 
and the stage could (more easily) generate non-narrative content. While stages in general can make these calls today, they do not have access to the user's jailbreak, and that makes it somewhat risky to incorporate this option at this time.
<br>
<br>
Perhaps future Stage improvements will permit stages to easily swap between positions and I can add functionality for displaying content in other places? 
Maybe it will be easier to load lorebooks or other bot details into the stage, and I could enable creators to leverage that data in who knows what kind of interesting ways? 
Could be the chat tree will become accessible, and you could do...something, I'm sure? Whatever comes, I will try to keep this stage on top of it, 
because I think this kind of stage holds value for people who want to play with these concepts but who don't want to build out their own stage to do so.
"

# 'PUBLIC', 'PRIVATE', or 'UNLISTED'.
visibility: 'UNLISTED'

# 'ADJACENT' | 'NONE' | 'COVER' | 'FULLSCREEN'
# 'ADJACENT' is default. The frame will display on the side of the
#   chat on desktop and above/in the top half of the chat on mobile.
# 'NONE' will not display, only run.
# 'COVER' will, indeed, cover the chat history completely,
#   but leave the text input box.
# 'FULLSCREEN' will make nothing below the header bar
#   show except for your stage.
position: 'NONE'

# Self-explanatory.
tags:
 - 'Stage'
 - 'Utility'
 - 'Stats'

# The schema of any user-supplied config.
# If your stage requires a configuration but has no
#   defined schema, it won't work.
# source: input/response/both
config_schema:
  title: Statosphere Settings
  type: object
  properties:
    configJson:
      title: Configuration
      description: Drop JSON from the Statosphere editor here--or paste this into the editor to make changes.
      type: string
      value: >
        {}
    debugMode:
      title: Debug Mode
      description: Leave disabled unless you don't care about stability.
      type: boolean
      value: false

# The schema of the state that you store.
# This isn't needed even if you do store state,
#   and is here more for future use cases to
#   optimize storage.
state_schema:
  init:
    type: object
    properties:
      grid:
        type: string
  message:
    type: object
    properties:
      angry:
        type: boolean
        default: true
  chat:
    type: object
    properties:
      visited:
        type: array
        items:
          type: integer

# Whether to publish as 'Anonymous' instead of under your username.
# is_anonymous: false

# Self-explanatory.
# ratings_disabled: false

# This is here for future cases where ex. you need user secrets,
#    but currently does nothing.
# permissions:

# extension_id is automatically generated on push with a new project;
#    you should not make or set this value.
# github_path will be added if it does not exist. It is the URL of the repo.


github_path: 'https://github.com/Lord-Raven/statosphere'


extension_id: 'statosphere-3704059fdd7e'

